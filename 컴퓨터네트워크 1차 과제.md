# Chapter 1
### P4.
***답*** : ***a.*** 16 / ***b.*** 8 / ***c.*** 가능하다.
***풀이*** 
 ![[Pasted image 20231014193443.png]]
***a.*** 최대 연결 수 = 16
	A<->B 연결을 4개 (, B<->C 연결을 4개, 
	C<->D 연결을 4개, D<->A 연결을 4개 수행하면,
	최대 16개 연결이 가능하다. (위 그림과 같이)
***b.*** A->C 사이에 가능한 연결 수 = 8개
	B를 거쳐서 가는, A, B, C를 연결하는 경우가 4개,
	D를 거쳐서 가는, A, D, C를 연결하는  경우가 4개이므로.
***c.*** 가능하다.
	A->C 사이의 4개의 연결에 대해
	2개 연결은 B를 거쳐서, 2개 연결은 D를 거쳐서 연결하면,
	B->D 사이에 4개의 연결을 수행할 수 있다.
	ex) (1번-5번), (2번-6번) 경로를 사용하여 A, B, C 를 연결하고,
		(9번-13번), (10번-14번) 경로를 사용하여 A, D, C를 연결하면
		B와 D의 연결은 :
		(7번-11번),(8번-12번),(3번-15번),(4번-15번)을 연결하여
		4개 연결을 수행하는 경우가 가능하다

### P8.
***답*** : ***a.*** 50명 / ***b.*** $p=0.1$ / ***c.*** $_{120}C_n * (0.1)^n * (0.9)^{120-n}$
	/ ***d.*** ![[Pasted image 20231019211022.png]]
***풀이***
10Mbps 링크를 사람이 나눠쓰고, 각 유저마다 200kbps를 보장받아야 함. 각 유저는 전체 시간 중 10%만 링크를 사용한다. 
***a.*** 50명에게 circuit을 제공할 수 있다.
	10Mbps / 200Kbps = 50 개의 circuit으로 나눌 수 있으므로
***b.*** p = 0.1 (10%)
	각각의 user들은 전체 시간 중 10%의 시간만 전송한다고 문제에서 정하였으므로, 어떤 사용자가 전송중일 확률 p = 0.1이다.
***c.*** $_{120}C_n * (0.1)^n * (0.9)^{120-n}$
	120명의 user에 중 $n$명의 유저가 전송중일 확률은,
	$(120명 중 n명을 고르는 경우의 수) * (p)^n * (1-p)^{120-n}$  이므로.
***d.*** 
	(51명 이상의 user가 동시에 전송중일 확률)은 곧,
	(1 - 50명 이하의 user가 동시에 전송중일 확률)과 같고, 이 때,
	$(50명\ 이하의\ user가\ 동시에\ 전송중일\ 확률)$
		$=\ (n=1일\ 때의\ 확률) + (n=2일\ 때의\ 확률)$  
			$+\ (n=3일 때의 확률) +\ ...\ + (n=50일 때의 확률)$ 로부터,
	다음과 같이 쓸 수 있다 :![[Pasted image 20231019211107.png]]
	이 확률을 실제 계산하려면, 다음과 같이 ***중심극한정리***를 이용한다 :	![[Pasted image 20231019213748.png]]
### P13. 
***답*** : ***(a)*** $N(N-1)L/2R$ / ***(b)*** $(N-1)L/2R$
***풀이***
***(a)*** $N(N-1)L/2R$ 
	동시에 N개 패킷이 도착한다 :
	처음 1번 패킷은 딜레이가 없고, 2번 패킷은 $L/R$만큼 기다린다. 3번 패킷은 $2L/R$만큼 기다린다. ... 마지막 패킷은 $(N-1)*L / R$ 만큼 기다린다, 따라서
	총 $0 + L/R + 2*L/R + ... + (N-1)*L/R$ = $N*(N-1)*L/2R$  만큼의 딜레이가 생긴다
	따라서 N개 패킷에 대한 평균 큐잉 딜레이는
	$N*(N-1)*L/2R$ 
***(b)*** $(N-1)L/2R$
	N개 패킷이 LN/R마다 주기적으로 도착한다 :
	먼저 N개 패킷이 동시에 도착하고 나면, 위와 같이 N개 패킷에 대한 평균 큐잉 딜레이는 $N(N-1)L/2R$이며, 이는 $LN/R$보다 작은 값이므로,
	매번 패킷을 받을 때는 큐가 비어있다
	이 때 각 패킷에 대한 평균 큐잉 딜레이는, 
	$(N(N-1)L/2R) / N$ = $(N-1)L/2R$ 

### P31. 
***답*** : ***a.*** 0.6초 / ***b.*** 0.002초, 0.004초 / ***c.*** 0.2초, (a)에 비해 약 3배 감소
	/ ***d.*** 와 ***e.*** : 풀이란에 서술
***풀이***
***a.*** *0.6s*
	store-and-forward 패킷스위칭을 사용하므로, 한 덩어리를 모두 받은 다음에서야 다음으로 보낼 수 있음
	segmentation 없이 보내므로, 1/5 = 0.2초를 기다려야 전체 덩어리를 다음 지점으로 보낼 수 있고, 2개의 패킷스위치를 지나므로, **3x0.2 = 0.6초**를 기다린다
***b.*** *(1) 0.002s, (2) 0.004s*
	첫 패킷이 source에서 first switch로, 즉 한 링크를 통과하는 시간은,
	0.01/5 = 0.002초 (1).
	첫 0.002초 지나면 첫 패킷이 first switch에 도착하고, 
	다음 0.002초 지나면 첫 패킷은 second switch에, 두 번째 패킷은 first switch에 fully received.
	따라서, 0.004초 (2).
***c.*** *0.2s*
	100개 패킷으로 나눈 결과, 각 패킷은 10000bit(0.01Mbit)임..
	각 패킷이 한 링크를 통과하는 시간은 ,  0.01/5 = 0.002초
	이렇게 한 링크를 통과하는 시간을 $t$라고 하면
	1번 패킷이 목적지에 도착한 경우, $3t$
	그럼 그 때, 1번 스위치에 3번 패킷, 2번 스위치에 2번 패킷이 위치
	$5t$ 경과하면, 1번 스위치에 5번 패킷, 2번 스위치에 4번 패킷이 위치
	보내는 패킷이 5개 뿐이라고 하면, 5번 패킷이 들어가려면 $2t$ 더
	$7t$ .. 5개 패킷에 7t 소요 : n개 패킷이면 $(n+2)t$
	따라서, **0.002 x 102 = 0.204초**
	*(a)에서 message segmentation 없이 보낼 때보다 3배 줄었다*
***d.*** delay를 줄이는 것 외에, message segmentation을 사용하는 이유는..
- message를 분할하지 않고 한꺼번에 보낼 경우, bit error 발생 시 전체 message를 다시 재전송해야할 수 있다.
- message를 분할하지 않고 한꺼번에 보낼 경우, 작은 크기의 message보다 앞서 크기가 큰 message(video 등...)가 router queue에서 전송중인 경우 이것이 모두 전송될 때까지 기다려야 하는 상황이 생길 수 있다.

***e.*** message segmentation의 단점을 논하시오.
- 목적지에 패킷을 보낼 때 순서를 지켜서 보내야 한다
- 각 패킷에는 헤더를 붙이게 되는데, 패킷을 잘게 분할을 할수록 그 수만큼 헤더를 각각 붙여야 하므로 헤더에 해당하는 용량이 그만큼 늘어나게 된다

# Chapter 2
### P9. 
***답*** : ***a***. 약 3.102초 / ***b***. 약 0.9초 정도
***풀이***
인터넷 네트워크에 대해, 
- access link는 54Mbps, LAN은 10Gbps, 
- object의 평균 사이즈는 1,600,000bit, 
- 서버로의 요청은 평균적으로 초당24회, 
- average internet delay는 평균 3초

***a***. total average response time = 약 3.102초
- 평균 접속 지연 = ![[Pasted image 20231019111029.png]] 
- ![[Pasted image 20231019111104.png]] = access link를 통해 객체를 보내는데 걸리는 시간 = 1.6Mbit/54Mbps = 0.0296..
- ![[Pasted image 20231019113333.png]] = (요청 수 = 24요청/s) * 0.0296 = 0.711 ...
- => ![[Pasted image 20231019111029.png]] = 0.102, 여기에 평균 인터넷 지연 3초를 더하면 ~3.102

***b***. total response time = 약 0.9초 수준
- miss rate인 0.3만큼은 access link를 지나 찾아와야하므로, 요청 수 = 24x0.3 = 7.2, 따라서 ![[Pasted image 20231019113333.png]] = 0.213...
- 이제 total average response time = 0.0376.. + 3 = 3.0376
- LAN에 대해, 1.6/10,000 = 0.00016으로부터.. 0.00016초의 LAN 딜레이가 발생하므로, 거의 무시할 수 있다
- 따라서, $0.3*3.0376$ ~= 0.911

### P20.
***답*** : $R_l > R_b$
***풀이***
	병목 링크를 통해 갔다 오는 경우($R_b$사용)에 비해, 기업 네트워크에서 해결하는 경우($R_l$사용)가 더 효율적일 경우, 프록시를 설치/사용하여 파일 전송 시간을 더 줄일 수 있다.

### P22.
***답*** : ![[Pasted image 20231019184022.png]]
*그림에서의 $D_{c-s}, D_{P2P}$는 각각 client-server distribution과 P2P distribution에 대한 minimum distribution time*
***풀이*** : 
- $F=10 Gbits$ / $u_s = 1Gbps$ / $d_i=200Mbps$
- client-server 일 경우 : 
	- 먼저, 서버에 파일$F$를 올린다 : $u_s$ upload rate : 1,000Mbps, 근데 N개 올려야 하므로.. $NF/u_s$ 
	- N개 client들은 $d_i = 200Mbps$로 F를 각자 다운로드 : $F/d_i$
	- 따라서, $D_{c-s} >= max(NF/u_s, F/d_i)$

- P2P일 경우 :
	- 분배가 시작되면 서버에 파일$F$를 올리는데, 하나만 있으면 됨 : $F/u_s$
	- 각 peer들은, 파일의 copy본을 $d_i = 200Mbps$로 각자 다운로드 : $F/d_i$
	- 또한 각 peer들을 포함하는 시스템의 전체 upload rate은 ![[Pasted image 20231019130052.png]](이 문제에서는 각 peer의 upload rate을 $u$로 하므로, $u_s + Nu$)이며, 시스템은 이 속도로 $NF\ bits$ 전달하므로, $NF/(u_s+Nu)$ 
	- 따라서 $D_{P2P} >= max(F/u_s,\ F/d_i,\ NF/(u_s+Nu))$