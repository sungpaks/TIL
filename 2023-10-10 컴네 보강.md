## 비트토렌트 리뷰
Alice peer가 그룹인 torrent에 참가하고자 하면 => 대표 격인 tracker에 참가를 신청하고, 그러고나면 각 peer들과 TCP연결할 수 있다. (peer 리스트를 받고, 주변 peer들과 연결하여 neighboring)
볼 일 끝나면 비트토렌트 끄고 연결 닫는다
- 파일 받을 때 : neighboring peer들에게,  필요한 청크를 요청보낸다 (어떤 peer가 어떤 청크를 갖는지 보고)
	- 받을 때 선택할 것 : 
		1. 청크 받고나면 다음에 어떤 청크 받을지 : neighboring peer들이 갖는 청크 중 가장 수가 적은(보기 드문) 청크를 요청한다. 
		2. 어떤 peer에게 청크를 요청할지. : peer들 사이에는 최대한 빠른 통신이 이루어져야 함을 원칙으로 함.
			1) 10초단위로, 가장 빠른 neighboring peer를 4개 선택한다 (top four)
			2) 30초단위로, 랜덤으로 neighbor가 아닌 peer중에 선택해본다. (더 빠르면 이 peer로 연결함)
			3) 앨리스 - 밥 예시

### video streaming.

stream video traffic : 인터넷 bandwidth를 거의 차지함. residential ISP 트래픽의 80%
만약 single mega server로 하면, 당연히 앞에서처럼, 트래픽 과부하 또는 속도 형평성 등의 이슈가 있겠죠? => distributed, application-level infrastructure => CDN

**video는 어떤 데이터인가??** 
- 여러 이미지의 일정 rate으로 연속되는 것
	- 이미지는 pixel로 이루어지며, pixel은 또 bit로 이루어진다.
- 데이터 압축 => 이미지를 구성하는 비트를 줄이고 전송한다 (coding)
	- spatial 방식 : 반복적인 색이 나오면, (1)색상값, (2)반복 횟수 이렇게 두 밸류만 보낸다
	- temporal 방식 : 이전 이미지에 비해 다른 부분만 보낸다
- CBR : constant(고정된) bit rate / VBR : variable(변함) big rate => spatial, temporal coding
- bit rate가 높으면 고화질이겠으나, 높은 capacity가 요구된다

video streaming할 때 해결해야 할 문제점??
서버에 저장된 stored video를 인터넷을 통해 client로 보내는 상황
- client마다 access network 속도가 상이하므로 일관적인 bit rate을 사용할 수 없음
	=> client의 상황에 따라 bit rate을 정해야함
- packet delay가 생길 수도 있고, congestion때문에 queueing delay가 생길 수도 있고, ..
	=> 그 결과로 재생이 늦어지거나 퀄리티가 저하되거나 등

서버에서 video를 보내면 누적으로 그래프가 올라가고, network delay만큼 지나고 client가 video를 받아서 그래프가 누적으로 또 올라간다
![[Pasted image 20231010185704.png]]
이렇게 (빨간색 : 서버가 보냄 / 파란색 : 클라이언트가 받음)
이 경우는 delay가 고정되어 보이지만, 실제론 다양한 네트워크 딜레이에 의해 이 delay가 상이하다. 
- buffering : 뒤의 데이터가 앞의 데이터보다 먼저 도착해버려서 기다림
	=> 이 playout을 맞추기 위해, client-side buffer 사용하여 쌓아뒀다가 보여준다
- client는 멈추거나, 뒤로/앞으로 감거나, 등...의 상호작용을 한다
- video packet이 손실,재전송될 가능성이 있다
![[Pasted image 20231010190033.png]]
client-side buffer를 사용 : 이렇게 된다는 거다. (검은 그래프 : 실제 , 파란색 : 클라이언트 화면 상에서 보여주는 양상) *compensate : 보정하다*

**HTTP 스트리밍 방식**이 있는데, request로 video를 요청하고 response 안에 video를 담아서 받고, client는 버퍼에 쌓았다가 보여준다.
- 실제 유튜브 등 많은 시스템에서 실제 적용되고 있으나..
- 모든 클라이언트가 bandwidth의 차이에도 불구하고 동일한 정도로 인코딩 된 비디오를 받는다.
=> 따라서 **DASH** 사용
## ***DASH***
: **D**ynamic, **A**daptive **S**treaming over **H**TTP
하나의 비디오 파일을 여러 청크로 나누고, 청크 단위로 보낸다. 이 청크는.. 청크별로 각기 다른 bit rate으로 coding하여 압축한다
- server
	- 청크들을 다양한 bit rate으로 압축
	- manifest 파일 : 다양한 비트율에 따른 각 버전의 URL을 제공함. 
		서버는 이걸 가지고 있다가, 
		클라이언트에서 이걸 요청하고 받아서 원하는 URL과 byt-range를 지정하여 request
- client
	- bandwidth를 계산하고, 네트워크 상황에 따른 bit rate의 청크를 요청하고 받는다 (Netflix에서 이 방식을 사용한다)
	- 언제 청크를 요청하며, 어떤 rate으로 요청할 것이며, 어디로 청크를 요청할 것인지 정해야함
		- when : 버퍼가 바닥나거나 꽉 차거나 하지 않도록
		- what encoding rate : bandwidth 상황에 따라
		- where : 가깝고 빨리 받을 수 있는 server로
**Streaming video** = encoding + DASH + playout buffering.

### ***CDNs***
: Content distribution networks
전세계의 사용자들에게 video를 제공해야 하는데.. 
- option 1 : single, large "mega-server"로는 못 버팀
- option 2 : 서버 클러스터를 어디에 놓느냐에 따라 갈린다
	- enter deep : 사용자 주변의 access ISP에 놓는다 (사용자랑 가깝게 깊이 놓는다). 
		- 장점 : 높은 throughput을 제공함
		- 단점 : 고도로 분산된 덕에 이 서버 클러스터의 유지/관리가 상당히 부담스럽다
		- Akamai 등
	- bring home : ISP 말고, POP(또는 IXP) 지점에 둔다: 
		- 장점 : 수가 많지 않아 유지보수가 좋다
		- 단점 : enter deep보단 좀 가깝지 않다
		- Limelight 등
	((ISP, IXP, POPs 등 => [[컴네 - 인터넷 네트워크 단위]]))
이렇게 서버를 세우고 나면, CDN은 콘텐츠를 copy하여 서버에 저장한다.
- 전부 가지고 있지는 않고, 자주 사용되는 콘텐츠만 store (실제로 CDN은 클러스터에 대해 push가 아닌 pull방식을 사용함)
- 혹여 로컬 클러스터에 없는 요청이 있으면, 이걸 중앙or다른 클러스터에서 받아와서 서비스하는 동시에 copy하여 클러스터에 저장함
- 웹 캐시 서버처럼, 용량이 가득 차면 자주 사용되지 않는 애들부터 지운다
manifest file을 열어본 client가 특정 URL로 비디오 재생을 요청하면 => CDN은 그 요청을 가로채 적당한 CDN서버로 연결시킨다 : 이 때 DNS를 이용

아마존 서버에서 CDN서버를 지정해주고.. 어쩌구

- OTT : Over The Top. 
	- 어디서 가져올거임 ? from which CDN server
	- congestion이 발생하면 viewer는 ? => manifest파일 열어보고 저화질 사용, or 머라고하셨는데
	- 각 CDN 서버에 어떤 컨텐츠를 둘지 (한국에선 인도영화보단 한국영화를 많이 둔다던지)
		- 웹 캐시 서버와 비슷한 느낌으로 ..
		- 용량이 차서 지울 때도 요청이 적은 순으로
- a closer look : netcinema 회사가 KingCDN(서드파티 회사)의 서버를 사용하는 경우
	1. local DNS서버를 통해 Bob이 요청을 하면, 
	2. netcinema의 DNS로 갔다가,
	3. KingCDN(실제 CDN서버)의 DNS로 가서 KingCDN의 IP주소를
	4. local DNS를 통해 IP주소 전달
	5. Bob은 해당 IP주소에서부터 비디오를 받는다
- case : Netflix => 아마존 클라우드 & 자체 CDN 인프라를 갖고 있다. 웹사이트 및 백엔드 DB들은 모두 아마존 클라우드에서 실행된다.
	- 아마존 클라우드 역할 : 
		- 콘텐츠 수집 : 영화를 수집 (처리 전)
		- 콘텐츠 처리 : 다양한 플레이어 기기들에 맞는, 또는 DASH를 위한 다양한 bit rate의 버전을 생성한다.
		- CDN으로 업로드 : 이렇게 다양한 버전을 생성하고 나면, CDN으로 업로드
	1. 재생할 영화 선택하면,
	2. 아마존 클라우드 위에 돌아가는 넷플릭스 소프트웨어에 의해, 해당 영화 사본을 가진 CDN서버를 결정
	3. 이 CDN서버들 중 클라이언트에게 최적인 CDN서버를 정한다
	4. manifest File(다양한 버전 URL을 담고 있음), 그리고 실제 통신할 특정 서버의 IP 전달


## socket programming with UDP & TCP
파이썬으로 이 socket 프로그래밍 예제 보여줌 등등
application layer는 process 단위로 이루어진다. 
종단 간 통신은, client 프로그램과 server 프로그램으로 구성되며, 두 프로그램을 수행하면 client process, server process가 각기 생성됨.
두 프로세스는 socket에서 read, 또는, socket에 write 하여 통신한다.
이 socket의 윗부분 (inteface)는 개발자 소관

파이썬 간단 socket code
1. client가 메시지(data)를 서버로 보내면
2. 서버는 data를 받고 uppercase로 변환한다
3. 이렇게 변환한 데이터를 client로 보낸다
4. client는 이렇게 받은 데이터를 출력한다

- UDP : 연결 X
	1) servername, serverPort를 알고 나서, server쪽에서 socket을 생성 : socket(AF_INET, SOCKET_DGRAM) 1번 인자 : IPv4, 2번 인자 : UDP
	2) client쪽에서 데이터를 보낸다 (`clientSocket.sendto(message.encode(), serverName, serverPort)`) 메시지는 인코딩됨
	3) server에서 serverSocket을 통해 받고나면, `decode.upper()`로 변경된 string을 다시 보낸다
- TCP : 연결 O : connection 과정 추가적으로 들어간다. 
	1) 먼저 연결 생성 과정 (`clientSocket.connection(serverName, serverPort)`)
	2) 나중에 문자열 보낼때는, 이미 connect되어있어서 문자열만 보낸다 (`connectionSocket.send(str)` 이런식으로)
	3) close()로 연결 닫는다

2장 끝


